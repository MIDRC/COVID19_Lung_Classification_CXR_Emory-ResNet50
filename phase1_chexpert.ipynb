{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing import image, image_dataset_from_directory\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "from focal_loss import BinaryFocalLoss\n",
    "from keras.layers import Dense, MaxPooling2D, Dropout, Flatten\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "from keras.callbacks import CSVLogger\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle, class_weight\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from focal_loss import BinaryFocalLoss\n",
    "from tensorflow_addons.losses import SigmoidFocalCrossEntropy\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('/home/jupyter-zaiman/data/DataCenter/CheXpert-v1.0/train.csv')\n",
    "data = data.filter([\"Path\", \"No Finding\"], axis=1)\n",
    "data = data.fillna(0)\n",
    "print(\"Before Undersampling...\")\n",
    "abnormal, normal = data[\"No Finding\"].value_counts()\n",
    "print(\"Abnormal: \" + str(abnormal))\n",
    "print(\"Normal: \" + str(normal))\n",
    "# Divide by class 0 = abnormal , 1 = nomral\n",
    "df_class_0 = data[data['No Finding'] == 0]\n",
    "df_class_0 = df_class_0.replace(0, 1)\n",
    "df_class_1 = data[data['No Finding'] == 1]\n",
    "df_class_1 = df_class_1.replace(1, 0)\n",
    "#abnormal = 1, normal = 0\n",
    "df_class_0_under = df_class_0.sample(normal, random_state=3)\n",
    "data = pd.concat([df_class_0_under, df_class_1], axis=0)\n",
    "data[\"No Finding\"] = data[\"No Finding\"].astype(str)\n",
    "print('After Undersampling:')\n",
    "print(data[\"No Finding\"].value_counts())\n",
    "data.head(30000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(data, test_size=0.4, random_state=1)\n",
    "valid, test = train_test_split(test, test_size=.5, random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#central crop on 224 x 224\n",
    "IMAGE_WIDTH, IMAGE_HEIGHT = (224, 224)\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 128\n",
    "learning = 0.001\n",
    "image_shape = (IMAGE_HEIGHT, IMAGE_WIDTH, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#zero mean to resize -1 to 1 \n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "    )\n",
    "valid_datagen = ImageDataGenerator(\n",
    "        rescale=1./255\n",
    "    )\n",
    "\n",
    "train_generator=train_datagen.flow_from_dataframe(\n",
    "    dataframe=train, \n",
    "    directory='/home/jupyter-zaiman/data/DataCenter/',\n",
    "    x_col=\"Path\", y_col=\"No Finding\", \n",
    "    class_mode=\"binary\", \n",
    "    target_size=(IMAGE_HEIGHT, IMAGE_WIDTH), \n",
    "    batch_size=BATCH_SIZE)\n",
    "valid_generator=valid_datagen.flow_from_dataframe(dataframe=valid, directory='/home/jupyter-zaiman/data/DataCenter/', x_col=\"Path\", y_col=\"No Finding\", class_mode=\"binary\", target_size=(IMAGE_HEIGHT, IMAGE_WIDTH), shuffle = True, batch_size=BATCH_SIZE)\n",
    "test_generator=valid_datagen.flow_from_dataframe(dataframe=test, directory='/home/jupyter-zaiman/data/DataCenter/', x_col=\"Path\", y_col=\"No Finding\", class_mode=\"binary\", target_size=(IMAGE_HEIGHT, IMAGE_WIDTH), shuffle = False, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create model\n",
    "base = tf.keras.applications.ResNet50(\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    pooling='max',\n",
    ")\n",
    "   \n",
    "for layer in base.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "for layer in [l for l in base.layers if 'conv5' in l.name]:\n",
    "    layer.trainable = True\n",
    "\n",
    "x = base.output\n",
    "x = Dense(512, activation = 'relu')(x)\n",
    "prediction = Dense(1, activation='sigmoid')(x)\n",
    "model = Model(inputs=base.input, outputs=prediction)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(lr=learning), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "save = ModelCheckpoint(\n",
    "    '/home/jupyter-zaiman/COVID-19 Classification/ResNet50-UnderSampling/', \n",
    "    monitor='val_accuracy', \n",
    "    save_best_only=True,\n",
    "    save_weights_only=True, \n",
    "    mode='max',\n",
    "    verbose=1\n",
    ")\n",
    "stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=6)\n",
    "scheduler = ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\",\n",
    "    factor=0.01,\n",
    "    patience=3,\n",
    "    verbose=1\n",
    "    )\n",
    "logger = CSVLogger('/home/jupyter-zaiman/COVID-19 Classification/ResNet50-UnderSampling/training.log')\n",
    "history = model.fit(train_generator, \n",
    "    epochs=EPOCHS, \n",
    "    validation_data=valid_generator, \n",
    "    verbose=1, \n",
    "    callbacks=[save, scheduler, stop, logger]\n",
    ")\n",
    "model.save('ResNet50_Undersampling.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='lower right')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='lower right')\n",
    "plt.show()\n",
    "    \n",
    "Y_pred = model.predict(test_generator, len(test_generator.filenames)) \n",
    "labels = (Y_pred >= 0.5).astype(np.int)\n",
    "print('Confusion Matrix')\n",
    "cm = confusion_matrix(test_generator.classes, labels)\n",
    "plt.figure(figsize=(6,6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\");\n",
    "target_names = ['Normal', 'Abnormal']\n",
    "print('Classification Report')\n",
    "print(classification_report(test_generator.classes, labels, target_names=target_names)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(test_generator.classes, Y_pred)\n",
    "\n",
    "def plot_roc_curve(fpr, tpr, label=None):\n",
    "    plt.plot(fpr, tpr, linewidth=2, label=label)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.axis([0, 1, 0, 1])\n",
    "    plt.title(\"ROC Curve\")\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "\n",
    "plot_roc_curve(fpr, tpr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "auc = roc_auc_score(test_generator.classes, labels)\n",
    "print(auc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
